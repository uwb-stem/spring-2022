{
    "csse": [
        {
            "time": "12:45 PM - 1:00 PM",
            "projectId": "csse-2-1245",
            "title": "Game Engine Supporting Resources",
            "studentName": "Myles Dalton",
            "studentMajor": "CSSE",
            "projectType": "Individual Project",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Myles Dalton.png",
            "abstract": "The 2D web game engine developed by Professor Sung is a complicated application programming interface (API) that allows developers to quickly create their own robust video games. The purpose of a game engine is to provide ready-made solutions to the implementation of common video game features, such as image sprites, realistic motion simulations, and scene lighting. Using these features as a developer requires detailed knowledge of the API’s functions. Previously, the only way to learn this information was by reading the 727-page textbook, studying the source code, or taking a class. In order to make the API more accessible I documented the complete source code and created tutorials on how to use its various features.\n\nTo ensure ease of access, the documentation and tutorials were written as websites using HTML and are hosted on the GitHub page of the engine. I used JSDoc 3 to automatically generate separate standardized, interlinked webpages from the internal source code documentation. These webpages clearly present information on the API’s functions that are in the normal video game developer use case. While the documentation provides a quick reference point for all experience levels, the tutorials are aimed at first-time game developers. The seven tutorials showcase how the many classes of the engine are designed to interact, alongside explanations of how and why to use them.\n\nThe difficulty of learning how to use the game engine API is a detraction from its viability as an educational tool for beginning developers. Ultimately, the publicly accessible websites for the documentation and tutorials can be valuable resources for independent developers and students."
        },
        {
            "time": "1:00 PM - 1:15 PM",
            "projectId": "csse-2-100",
            "title": "Collaborative 3D Gallery Space",
            "studentName": "Nathan Miller",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Nathan Miller.png",
            "abstract": "The following capstone was done under the Cross-Reality Collaboration Sandbox (CRCS) research group and the overall goal was to create a virtual learning environment. The application is a multi-user virtual learning space where students and teachers can meet to share ideas through drawings. Drawings from all students and teachers are hung on the walls of the environment resembling an art gallery or an art walk. This format allows all teachers and students to learn about different ideas on the same topic being taught within a confined space.\n\nMost virtual classrooms experience the issue of engaging students in course content while also struggling to develop a sense of community. Factors that may cause this issue is students' reluctance to participate with people they may not know well, not many options are given to students to co-mingle, and teachers have a hard time getting feedback.\n\nStudents can communicate by drawing, typing, or importing images onto their own canvas. The variety of tools are designed to cater to students' preferred strengths since some students are more inclined to draw than type their answers and vice versa. When a student submits their work everyone in the class can see what they have submitted on the walls without their username being attached to the work. This helps circumvent the fear of being wrong in front of everyone since nobody will know who has submitted a canvas.\n\nThis project was split among a group of four people who worked on individual tasks to achieve the final product. The part I contributed to is switching the user in between drawing and submitting for the gallery. This included spawning all of the canvases on the wall when the teacher started the gallery, changing the gallery space to fit an influx of paintings, individuals submitting to the gallery, voting on individual students' work, and shutting the lobby down. \n\nThe overall application is unique since multiple avenues are given to the user to communicate their ideas in correlation with the way those ideas are presented in the given space. The takeaways learned from this capstone is that software development is a continuous cycle of presenting new ideas and refining those concepts into a final product. Without the proper communication and planning, sorting out these ideas into programming tasks would be difficult."
        },
        {
            "time": "1:15 PM - 1:30 PM",
            "projectId": "csse-2-115",
            "title": "Collaborative 3D Gallery Space",
            "studentName": "Tyler Miller",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Tyler Miller.png",
            "abstract": "This capstone project was completed as a part of the Cross-Reality Collaboration Sandbox research group headed by Kelvin Sung. What was built during this capstone was a virtual classroom that allows the teacher to display a question and students are able to answer that question through drawing by using a mouse and typing using a keyboard. When the students are done answering the question the instructor will post each response on the walls of the class in which the students can walk around and vote on their favorite solutions. \n\nThis capstone was made to bridge the gap of communication between peers and instructors for future pandemics. Instructors had a hard time posting questions that required work to be shown like in any mathematics course. These types of questions were hard to answer on current meeting platforms because not all students are able to answer without the other students seeing their work. \n\nThe results of this project is a virtual classroom in which students can respond to questions posted by the instructor. Each individual gets a canvas to draw and type on. The user can change the color of brush, create straight lines for a graph, and type equations on their specific canvas. These implementations were centered on being used for more STEM related fields. The option to include both typing and drawing allows the user freedom to come up with the solution in which they think is best portrayed. Some people like to make side notes about the problem they are solving which is why the drawing tool is in this system.\n\nThis was a group project amongst four people. I worked on saving and loading a png on the canvas. I worked on the drawing and erasing on the canvas. I implemented the color change and size on the brush. In addition, I implemented the text feature with two different resolutions. I also worked on the canvas shrinking and growing on request of teacher help. I also worked on singling out the user with the most votes. \n\nTo conclude, this project expands online interaction between teachers and students. What was learned is that creating a virtual classroom allows for more indirect interactions between students and teachers and allows for ideas to be shared easier through the use of the gallery."
        },
        {
            "time": "1:30 PM - 1:45 PM",
            "projectId": "csse-2-130",
            "title": "Collaborative 3D Gallery Space",
            "studentName": "Gary Yuen",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Gary Yuen.jpg",
            "abstract": "This capstone project was produced under the supervision of the Cross-Reality Collaboration Sandbox (CRCS) and Professor Kelvin Sung in order to supplement a virtual learning environment. The application that was created during this project was a virtual gallery that allows users to create and share work done in class in a virtual environment, which allows teachers and students to better participate in learning.\n\nWithin all classrooms, students are reluctant to share their ideas, which was exacerbated by the shift to virtual learning. By allowing students to share their answers with anonymity, they will be more willing to let their classmates see. Furthermore, with teachers only able to see those that need help, they will be able to gauge the overall progress of the class and better help those in need. Using the Augmented Space Library from the CRCS, the application is able to perform networked tasks, allowing for users to connect from their own homes.\n\nThis application allows all users to draw on a canvas and share it with the class. The teacher in particular is able to see all the students in the room with a Zoom-styled scrollbar at the top of the screen. This bar reflects the students that need help, as well as a preview of their work. Students are able to see the teacher’s canvas at all times, but can’t see other students’ work. When the teacher starts the gallery, students are not obligated to immediately submit, and can look at other students’ work for inspiration.\n\n Within the team environment, my part was the design of the user interface (UI) as well as elements of the networking between users and the server. Namely, the teacher’s scrollbar and user movement were what I worked on, as well as the overall usability of the UI. This taught me to be considerate of not only what my team was working on, given that UI changes in Unity are harder to merge than code, but also what is comfortable for the end-users.\n\nThroughout this project, the process of development was continuous, allowing for constant improvements and refining of the end product. This helped to instill the importance of consistent communication and understanding of requirements, especially when working in a team."
        },
        {
            "time": "1:45 PM - 2:00 PM",
            "projectId": "csse-2-145",
            "title": "Lecture Board Game",
            "studentName": "Isabella Abad",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Isabella Abad.png",
            "abstract": "This capstone project was done as part of the Cross-Reality Collaboration Sandbox research group led by Kelvin Sung. The goal of this capstone was to create a virtual learning environment and the application made is a educational online board game meant to be used during a lecture. \n\nVirtual classrooms have trouble keeping students engaged and paying attention. When teachers ask the class a question, it’s rare for someone to offer an answer right away which in a lot of cases leads the teacher to calling on a random student. This doesn’t allow the teacher to properly understand the class’s overall understanding of the lecture. In the application, teachers upload questions related to the lecture. Students will have to answer them and mark if they were correct or incorrect in order to move around the board and earn points. The teacher is able to see how many students marked themself as correct and all the submitted answers.\n\nI created the question buttons, UI to answer and selfgrade the questions which allows students to not be pressured like they would be when called on in class. I also created the teacher version of the question button which contains the overall stats of how many have answered as well as the UI to create or save new questions. When students get the question right, they get five stars and a dice. When they roll the dice, their player piece will move accordingly to the roll. I created the player pieces from scratch as well as the wiggle animation when they move. The board has effect tiles that can give them stars, take away stars, make them attempt to steal stars from a fellow student, give them a bonus question, or teleport them to a random location. I made the icons as intuitive as I could based on several different popular games and I made sure to lay them out evenly across the board.\n\nIn conclusion, this project makes a lecture more engaging and retains the student’s attention longer than a normal zoom lecture. The process of creating this game was a continuous cycle of getting feedback and improving the application based on flushing out original ideas and said feedback. The takeaway is the importance of constant communication and understanding the viewpoint of all possible users. "
        },
        {
            "time": "2:00 PM - 2:15 PM",
            "projectId": "csse-2-200",
            "title": "Lecture Board Game",
            "studentName": "Britney Kuoch",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Britney Kuoch.jpg",
            "abstract": "Our goal was to produce an application that makes virtual learning more engaging and interactive. The form of remote learning we’re familiar with utilizes video conferencing software like Zoom for lectures. To address some issues with online lectures, we created a board game application that can be used during a lecture.\n\nFor teachers, a problem with online lectures is that they can’t see participation since cameras are often off. Also faced with a lack of questions from students, teachers cannot get a good grasp on how well students understand the lecture. Teachers may ask for students to answer practice questions, but the teacher won’t be able to get answers from every student.\n\nFor students, it’s easy to get distracted when your camera is off. Also, teachers often use lecture slides, which are provided to students. Having these slides make students less likely to write their own notes, which is bad because writing notes help students engage with and remember the material.\n\nOur board game can engage students without being too distracting because we simplified the gameplay, reducing the attention required. Our application allows the teacher to post questions for students to answer. The teacher can see question data including how many students answered, how many got it right, and all student responses. The student can earn a dice and some stars when answering correctly. A dice can be rolled, allowing the student to move their player piece around the board, triggering tile effects and stealing stars by passing other players. After the teacher ends the game, the winner would be the student with the most stars. A csv report can be downloaded, allowing the teacher to keep a record on how the students did and the students to get notes they can study.\n\nIn this project, I was responsible for implementing the player grouping, end game UI, downloadable csv report, teacher view of student answers, and star ranking. Multiplayer networking was implemented using Augmented Space Library (ASL), developed by Cross Reality Collaboration Sandbox (CRCS). The development process was iterative. Every week, we had a standup, got feedback, and made adjustments. After each playtest, we made adjustments based on feedback. Through our application, we explored how to use a game for education. We used data and analysis to guide our thinking when maintaining the balance between lecture and game engagement. "
        }, 
        {
            "time": "2:15 PM - 2:30 PM",
            "projectId": "csse-2-215",
            "title": "CourseXpo: A Collaborative Virtual Learning Environment",
            "studentName": "Andy Tran",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Andy Tran.png",
            "abstract": "The physical world can be seen as a constraint on learning. When asked to think of what a classroom looks like, a person may imagine rows of desks and chairs with a teacher on one side of the room with maybe a podium, projector screen, and a whiteboard. Some may even reference online learning and imagine each student sitting at their computer watching a live feed of the teacher's screen while they deliver their lecture to a grid of still images. CourseXpo is a project we created to reimagine the learning environment by creating a system in a digital space and integrating technologies like Virtual Reality.\n\nThe CourseXpo application was built with Unity game engine and uses the Augmented Space Library (ASL) developed by the Cross Reality Collaboration Sandbox (CRCS) Research Group. With these tools, we as a team of four were able to create a modular Expo-style environment where students can wander around, interact with one another, and consume learning material at their own pace.\n\nIn this project, I was responsible for using ASL to make sure components were communicating with each other properly. I also found course material to perform demos with and accomplished work on the VR side of our application. Other responsibilities included producing reports, incorporating feedback, and organizing tasks into an easy format to follow. From this project, I was able to gain experience reading and understanding documentation, adapting to new software updates, and collaborating with a group of self-motivated individuals.\n\nThe result was an app where player controls are smooth and consistent across platforms. Course material can be sent from teacher to student with ASL and the GameLift RealTime Servers it was built on. We've constructed our own idea of a classroom as a virtual environment that acts like a learning management system (LMS). By the end of our quarter-long journey, we were able to build a starting foundation towards a new way to learn with plenty of opportunities to expand upon our work."
        },
        {
            "time": "2:30 PM - 2:45 PM",
            "projectId": "csse-2-230",
            "title": "CourseXpo: A Collaborative Virtual Learning Environment",
            "studentName": "Connor Leonie",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Connor Leonie.png",
            "abstract": "The physical world can be seen as a constraint on learning. When asked to think of what a classroom looks like, a person may imagine rows of desks and chairs with a teacher on one side of the room with maybe a podium, projector screen, and a whiteboard. Some may even reference online learning and imagine each student sitting at their computer watching a live feed of the teacher's screen while they deliver their lecture to a grid of still images. CourseXpo is a project we created to reimagine the learning environment by creating a system in a digital space and integrating technologies like Virtual Reality.\n\nThe CourseXpo application was built with Unity game engine and uses the Augmented Space Library (ASL) developed by the Cross Reality Collaboration Sandbox (CRCS) Research Group. With these tools, we as a team of four were able to create a modular Expo-style environment where students can wander around, interact with one another, and consume learning material at their own pace.\n\nMy part of our project primarily focused on QOL features, UI implementation, and ease of access to anywhere within the content provided. The issues that arose were the need to create an environment that can function in tandem with the user and creating a UI and transport system that clearly displayed to the user how it functioned. From this project, I was able to gain a better understanding of maintaining clear communication with a group of individual developers and adapting existing systems to function as the end-user instead of what the developer expects them to.\n\nThe creation was a smooth user-friendly experience that allows anyone to step into the program with little prior knowledge and get to where they want to learn efficiently either by walking through in-environment teleporters or instantly through a booth list. Any temporary information is saved as a backup in case a user forgets what they are doing or need to do. The final result is that users are never limited by either attention, time, or location for their individual learning and can learn both at their pace without missing out on any manual instruction and providing a foundation for providing a truly customizable remote teaching environment."
        },
        {
            "time": "2:45 PM - 3:00 PM",
            "projectId": "csse-2-245",
            "title": "CourseXpo: A Collaborative Virtual Learning Environment",
            "studentName": "Derek Slater",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Derek Slater.png",
            "abstract": "The physical world can be seen as a constraint on learning. When asked to think of what a classroom looks like, a person may imagine rows of desks and chairs with a teacher on one side of the room with maybe a podium, projector screen, and a whiteboard. Some may even reference online learning and imagine each student sitting at their computer watching a live feed of the teacher's screen while they deliver their lecture to a grid of still images. CourseXpo is a project we created to reimagine the learning environment by creating a system in a digital space and integrating technologies like Virtual Reality.\n\nThe CourseXpo application was built with Unity game engine and uses the Augmented Space Library (ASL) developed by the Cross Reality Collaboration Sandbox (CRCS) Research Group. With these tools, we as a team of four were able to create a modular Expo-style environment where students can wander around, interact with one another, and consume learning material at their own pace.\n\nMy role in our project consisted largely of our video player functionality, player interaction and communication, and the physical structure and atmosphere of the environment that our application contains. The main challenges in the implementation of my features were mainly around ensuring that they felt smooth, polished, and intuitive. From this experience, I learned to be able to implement and improve our application based on user feedback within a four-person group collaboratively and iteratively.\n\nThe final outcome was a synchronous (via ASL) and asynchronous video player with inspirations from the commonly known YouTube player, moderately realistic lighting, and texturing that aids in the immersion of the space, and interaction between players that helps to make it feel like they’re truly there alongside one another. Ultimately, it allows for an experience that can help facilitate learning between both PC and VR users and provides a baseline for future developers and researchers in the area of remote learning."
        },
        {
            "time": "3:00 PM - 3:15 PM",
            "projectId": "csse-2-300",
            "title": "CourseXpo: A Collaborative Virtual Learning Environment",
            "studentName": "Patrick Miles",
            "studentMajor": "CSSE",
            "projectType": "Faculty Research",
            "facultyAdvisor": "Dr. Kelvin Sung",
            "posterLink": "./posters/csse/Patrick Miles.png",
            "abstract": "The physical world can be seen as a constraint on learning. When asked to think of what a classroom looks like, a person may imagine rows of desks and chairs with a teacher on one side of the room with maybe a podium, projector screen, and a whiteboard. Some may even reference online learning and imagine each student sitting at their computer watching a live feed of the teacher's screen while they deliver their lecture to a grid of still images. CourseXpo is a project we created to reimagine the learning environment by creating a system in a digital space and integrating technologies like Virtual Reality.\n\nThe CourseXpo application was built with Unity game engine and uses the Augmented Space Library (ASL) developed by the Cross Reality Collaboration Sandbox (CRCS) Research Group. With these tools, we as a team of four were able to create a modular Expo-style environment where students can wander around, interact with one another, and consume learning material at their own pace.\n\nA large part of my role in this project was setting up a system to load pre-made content in at runtime, and a portion of that was working with ASL to send the content in a meaningful way using the protocols already present in the API. I was also responsible for some of the display and exportation of meaningful stats about the expo booths for both students and teachers alike. The main objective of these solutions is to provide a way to insert learning materials into the program and to provide analytics about those learning materials to the required parties. During the development of this project, I learned how to better work with my self-driven peers, how to digest and use large APIs, and user-focused feedback-driven development.\n\nThe result of our efforts is a system that allows content to be shared in real-time in an interactive environment very quickly, as well as the system to analyze that user interaction with the system. This system that we have set up will allow future developers to add their own content via an extensible file format to hold new types of educational content, as well as metrics to monitor the progress of that new content."
        }
                         
    ]
}